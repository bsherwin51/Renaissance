{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b863766-1499-4abc-8600-5977770381b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys, os, time\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8eca66c3-253d-462d-977a-9873b39402de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = h.File('catalog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ae0c586-a160-4ccb-ba34-fff8fef4a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_halo_props_at_all_z = {}\n",
    "for halo in ds.keys():\n",
    "    halo_props_at_all_z = {}\n",
    "    for idx, z in enumerate(list(ds[halo]['redshift'])):\n",
    "        if list(ds[halo]['fesc'])[idx] >= 1e-5:\n",
    "            halo_props_at_all_z[z] = [list(ds[halo]['SFR'])[idx], list(ds[halo]['Mstar'])[idx], list(ds[halo]['mass'])[idx], \\\n",
    "                                          list(ds[halo]['fgas'])[idx], list(ds[halo]['redshift'])[idx], list(ds[halo]['fesc'])[idx]]\n",
    "    #if len(list(halo_props_at_all_z.keys())) == 0:\n",
    "    #    continue\n",
    "    all_halo_props_at_all_z[halo] = halo_props_at_all_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bbcae37-19d4-4109-99df-e021a495de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshifts40 = []\n",
    "for halo in ds.keys():\n",
    "    if len(list(ds[halo]['redshift'])) == 40:\n",
    "           redshifts40 = list(ds[halo]['redshift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e96f99a-b3ee-4380-aeec-2fb211d991da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_properties = []\n",
    "for halo_idx, halo_num in enumerate(list(all_halo_props_at_all_z.keys())):\n",
    "    halo_props = []\n",
    "    temp = all_halo_props_at_all_z[halo_num].keys()\n",
    "    try:\n",
    "        min_props = all_halo_props_at_all_z[halo_num].get(max(temp))\n",
    "    except:\n",
    "        continue\n",
    "    for redshift in redshifts40:\n",
    "        if redshift not in temp:\n",
    "            halo_props.append(min_props)\n",
    "        else:\n",
    "            halo_props.append(all_halo_props_at_all_z[halo_num].get(redshift))\n",
    "    all_properties.append(halo_props)\n",
    "all_properties_reshape = np.reshape(np.array(all_properties), (151,40,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "782e19cc-d22a-470c-8c37-d7fb12463952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_properties_reshape\n",
    "y = all_properties_reshape[:,:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb9bbf07-a5cb-4a0d-a769-8dea5b1659d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X[15:,:,0:5])\n",
    "y_train = torch.Tensor(y[15:,:])\n",
    "X_val = torch.Tensor(X[:15, :, 0:5])\n",
    "y_val = torch.Tensor(y[:15, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75f4d61a-4624-4efe-aa37-46cfeb26508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1724, 0.1183, 0.0720, 0.0463, 0.1055, 0.0710, 0.0449, 0.0253, 0.4159,\n",
      "        0.4159, 0.4159, 0.0146, 0.0164, 0.4159, 0.0073, 0.4159, 0.0184, 0.0343,\n",
      "        0.0316, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159,\n",
      "        0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159,\n",
      "        0.4159, 0.4159, 0.4159, 0.4159])\n"
     ]
    }
   ],
   "source": [
    "single_halo_x = X_train[0]\n",
    "single_halo_y = y_train[0]\n",
    "print(single_halo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842ae34-a687-4d05-a83a-0c7e7f21dce6",
   "metadata": {},
   "source": [
    "## Template LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6dd893e5-0420-4ba2-8849-f942e790ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 10\n",
    "train_set = single_halo_x[:-test_size]\n",
    "test_set = single_halo_x[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db837ff5-7bf7-410e-b4cb-c3923d64169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(seq,ws):\n",
    "    out = []\n",
    "    L = len(seq)\n",
    "    \n",
    "    for i in range(L-ws):\n",
    "        window = seq[i:i+ws]\n",
    "        label = seq[i+ws:i+ws+1]\n",
    "        out.append((window,label))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bf46fbb-5cc8-4876-81b7-267c3616009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 10\n",
    "train_data = input_data(train_set, window_size)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e093c84-7d02-4421-8d81-4f76b9d61378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size = 5, hidden_size = 50, out_size = 1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,out_size)\n",
    "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
    "    \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc2ee1e3-2126-4aec-8450-c29554a5cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f207a7d3-559c-4cfe-914b-1d86ec6e5093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 135735143301120.0\n",
      "[[0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273]]\n",
      "[[0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], [0.00017505112919025123, 3501.0224609375, 28871420.0, 0.0886339396238327, 17.301610946655273], 6982911.0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(model(seq)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(preds)\n\u001b[0;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, single_halo_y[\u001b[38;5;241m-\u001b[39mwindow_size\u001b[38;5;241m-\u001b[39mtest_size:\u001b[38;5;241m-\u001b[39mtest_size])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerformance on test range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: not a sequence"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "future = 1\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for seq, y_train in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = (torch.zeros(1,1,model.hidden_size),\n",
    "                       torch.zeros(1,1,model.hidden_size))\n",
    "        \n",
    "        y_pred = model(seq)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {i} Loss: {loss.item()}\")\n",
    "    \n",
    "    preds = train_set[-window_size:].tolist() # train_set is single_halo_x[:-test_size]\n",
    "    print(preds)\n",
    "    seq = torch.FloatTensor(preds[-window_size:])\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1,1,model.hidden_size),\n",
    "                       torch.zeros(1,1,model.hidden_size))\n",
    "        preds.append(model(seq).item())\n",
    "    print(preds)\n",
    "    loss = criterion(torch.tensor(preds[-window_size:]), single_halo_y[-window_size-test_size:-test_size])\n",
    "    print(f\"Performance on test range: {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021589b5-531d-4d4c-8ac6-fa4b01cc2398",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7cb6389-380e-454f-8ede-a79b58819000",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a740499-28f0-432a-a24a-fcb0c6316255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(seq,ws,labels):\n",
    "    out = []\n",
    "    L = 40\n",
    "    counter = 0\n",
    "    for i in range(L-ws-1):\n",
    "        if counter > 130:\n",
    "            break\n",
    "        window = seq[counter:counter+10,i:i+ws,:]\n",
    "        # print(window.shape)\n",
    "        label = labels[counter:counter+10,i+ws:i+ws+1]\n",
    "        # print(label.shape)\n",
    "        counter+=10 \n",
    "        out.append((window,label))\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "62a5d463-b253-4e65-8770-5b334dd3bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[(10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (10, 20, 5), (6, 20, 5)]\n"
     ]
    }
   ],
   "source": [
    "train_data = input_data(X_train, 20, y_train)\n",
    "print([len(t) for t in train_data])\n",
    "print([len(t[0]) for t in train_data])\n",
    "print([len(t[1]) for t in train_data])\n",
    "print([(t[0].numpy().shape) for t in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f661ebf-0804-4b8d-a8ed-010b1dab021c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dea1dc42-e87f-4142-92e6-7a89d9a97536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMnetwork(nn.Module):\n",
    "    def __init__(self,input_size= 5,hidden_size=5,output_size=1): # should be input 5 hidden 1 output 1\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # add an LSTM layer:\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size, batch_first = True)\n",
    "        \n",
    "        # add a fully-connected layer:\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "        # initializing h0 and c0:\n",
    "        self.hidden = (torch.zeros(1,136,self.hidden_size), # should be 1, 136\n",
    "                       torch.zeros(1,136,self.hidden_size)) # should be 1, 136\n",
    "\n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            seq.view(len(seq),1,-1), self.hidden)\n",
    "        pred = self.linear(lstm_out.view(len(seq),-1))\n",
    "        return pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1d874a67-b44b-4026-a50a-db88b5a434c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMnetwork(\n",
       "  (lstm): LSTM(5, 5, batch_first=True)\n",
       "  (linear): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# instantiate\n",
    "model = LSTMnetwork()\n",
    "\n",
    "# loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "98c4d305-99c1-4280-9d86-4e037544fa10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 5, got 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m136\u001b[39m,model\u001b[38;5;241m.\u001b[39mhidden_size), \u001b[38;5;66;03m# should be 1, 136\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m136\u001b[39m,model\u001b[38;5;241m.\u001b[39mhidden_size)) \u001b[38;5;66;03m# should be 1, 136\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, target)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[108], line 17\u001b[0m, in \u001b[0;36mLSTMnetwork.forward\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,seq):\n\u001b[0;32m---> 17\u001b[0m     lstm_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(seq),\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:767\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    770\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:692\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    688\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    689\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    690\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    691\u001b[0m                        ):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    694\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    696\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 5, got 100"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for seq, target in train_data:\n",
    "        print(seq.shape)\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = (torch.zeros(1,136,model.hidden_size), # should be 1, 136\n",
    "                        torch.zeros(1,136,model.hidden_size)) # should be 1, 136\n",
    "        \n",
    "        y_pred = model(seq)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:2} Loss: {loss.item():10.8f}')\n",
    "    \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c13d41e2-2c83-4acb-98ac-ec08e0d72d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 5 at dim 1 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(future):\n\u001b[0;32m----> 8\u001b[0m     seq \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     10\u001b[0m         model\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,model\u001b[38;5;241m.\u001b[39mhidden_size),\n\u001b[1;32m     11\u001b[0m                         torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,model\u001b[38;5;241m.\u001b[39mhidden_size))\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 5 at dim 1 (got 1)"
     ]
    }
   ],
   "source": [
    "future = 10\n",
    "\n",
    "preds = y_train[-window_size:].tolist()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i in range(future):\n",
    "    seq = torch.FloatTensor(preds[-window_size:])\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1,1,model.hidden_size),\n",
    "                        torch.zeros(1,1,model.hidden_size))\n",
    "        preds.append([t.numpy() for t in model(seq)])\n",
    "preds[window_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1d35c-7627-430b-b874-877df7bcdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[-window_size:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bf607-72b2-4645-b4eb-d29390ba65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16053a8-8142-4d1e-8511-18be47a33cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
